{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND2PRgvrWYyd",
        "outputId": "ebc0b169-4103-4a25-f3cb-df96652952e6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2, os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models, datasets\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"cuda available? \" + str(torch.cuda.is_available()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOp0odesW_7f",
        "outputId": "47954565-3e04-4c22-8005-84da11123965"
      },
      "outputs": [],
      "source": [
        "# Define root directory from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "root_dir = \"/content/drive/My Drive/ceilometer_dataset1.1/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAUmm9PbYCUg"
      },
      "outputs": [],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize((299,299)),\n",
        "    transforms.RandomResizedCrop(299),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.425,0.415,0.405),(0.205,0.205,0.205))\n",
        "])\n",
        "\n",
        "# Augmentation on test images not needed\n",
        "transforms_test = torchvision.transforms.Compose([\n",
        "    transforms.Resize((299,299)),\n",
        "    transforms.RandomResizedCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiKjITTrXsPn"
      },
      "source": [
        "Structure of dataset folders\n",
        "```\n",
        "ceilometer_dataset\n",
        "    ----> train\n",
        "          ---->true\n",
        "          ---->false\n",
        "    ----> test\n",
        "          ---->true\n",
        "          ---->false\n",
        "\n",
        "70% train, 30% test\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7Vu-B3pXotq"
      },
      "outputs": [],
      "source": [
        "# remember to modify placeholders!\n",
        "train_dir = root_dir + \"train/\"\n",
        "test_dir = root_dir +\"test/\"\n",
        "train_classa_dir = root_dir + \"train/true/\"\n",
        "train_classb_dir = root_dir + \"train/false/\"\n",
        "test_classa_dir = root_dir + \"test/true/\"\n",
        "test_classb_dir = root_dir + \"test/false/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcskWC7QXwgY"
      },
      "outputs": [],
      "source": [
        "train_datasets = datasets.ImageFolder(train_dir, transforms_train)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transforms_test)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_datasets, [round(len(train_datasets)*0.70), round(len(train_datasets)*0.30)])\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=2, drop_last=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=12, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=12, shuffle=False, num_workers=2, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2-1wtjpXz6j",
        "outputId": "011a9bbf-efc8-4c6b-8cd7-17225d63f6a1"
      },
      "outputs": [],
      "source": [
        "print('Train dataset size:', len(train_dataset))\n",
        "print('Validation dataset size:', len(val_dataset))\n",
        "print('Test dataset size:', len(test_dataset))\n",
        "class_names = test_dataset.classes\n",
        "print('Class names:', class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "KtxM6UW5X2JY",
        "outputId": "03bd4d0d-f4d2-4c14-c6d2-a8d3e41a690d"
      },
      "outputs": [],
      "source": [
        "# Random checking of train images\n",
        "im, label = train_dataset[100]\n",
        "print(im.shape)\n",
        "print(\"-------------\")\n",
        "print(label)\n",
        "plt.imshow(im.permute(1,2,0).cpu())\n",
        "print(\"Class: \", class_names[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4aBDe-yYi4J",
        "outputId": "689ea1c8-d3e4-4022-bec9-174b6e9e34a7"
      },
      "outputs": [],
      "source": [
        "#Downloading the InceptionV3 Model with their pretrained weights\n",
        "\n",
        "model = models.inception_v3(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()  #(set loss function)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_UyEpXxpQzm",
        "outputId": "4d48ef87-448f-47b2-d7c5-f875ebbaae1b"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LSiLsXJl9ib"
      },
      "outputs": [],
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = np.inf\n",
        "\n",
        "    def early_stop(self, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFb2nH-mYmHC"
      },
      "outputs": [],
      "source": [
        "# Initialize training history\n",
        "# Initialize history\n",
        "history_loss = {\"train\": [], \"val\": [],\"test\": []}\n",
        "history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
        "history_f1 = {\"train\": [], \"val\": [], \"test\": []}\n",
        "history_precision = {\"train\": [], \"val\": [], \"test\": []}\n",
        "history_recall = {\"train\": [], \"val\": [], \"test\": []}\n",
        "\n",
        "# Initialize best validation accuracy and test accuracy at best validation accuracy\n",
        "best_val_accuracy = 0\n",
        "best_test_accuracy = 0\n",
        "best_test_f1 = 0\n",
        "best_test_precision = 0\n",
        "best_test_recall = 0\n",
        "save_test_value = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bnj7PBgTZw5c",
        "outputId": "dd27dd10-c898-41ea-cd5a-2bb9ede9df30"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60   #(set no of epochs)\n",
        "early_stopper = EarlyStopper(patience=3, min_delta=0.05)\n",
        "start_time = time.time() #(for showing time)\n",
        "for epoch in range(num_epochs): #(loop for every epoch)\n",
        "    print(\"Epoch {} running\".format(epoch)) #(printing message)\n",
        "    \"\"\" Training Phase \"\"\"\n",
        "    model.train()    #(training model)\n",
        "    running_loss = 0   #(set loss 0)\n",
        "    running_corrects = 0\n",
        "    running_labels_preds = {\"labels\": [], \"preds\": []}\n",
        "\n",
        "    # load a batch data of images\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # forward inputs and get output\n",
        "        optimizer.zero_grad()\n",
        "        outputs, _  = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # get loss value and update the network weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # store labels and preds and calculate f1, precision and recall at the end of the epoch\n",
        "        running_labels_preds[\"labels\"].append(labels.to('cpu').data.numpy())\n",
        "        running_labels_preds[\"preds\"].append(preds.to('cpu'))\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
        "\n",
        "    epoch_labels = np.concatenate((running_labels_preds['labels'][0],running_labels_preds['labels'][1]), axis=None)\n",
        "    epoch_preds = np.concatenate((running_labels_preds['preds'][0],running_labels_preds['preds'][1]), axis=None)\n",
        "    for i in range(2, len(running_labels_preds['labels'])):\n",
        "      epoch_labels = np.concatenate((epoch_labels,running_labels_preds['labels'][i]), axis=None)\n",
        "      epoch_preds = np.concatenate((epoch_preds,running_labels_preds['preds'][i]), axis=None)\n",
        "\n",
        "    epoch_f1 = f1_score(epoch_labels, epoch_preds)\n",
        "    epoch_precision = precision_score(epoch_labels, epoch_preds)\n",
        "    epoch_recall = recall_score(epoch_labels, epoch_preds)\n",
        "\n",
        "    history_loss[\"train\"].append(epoch_loss)\n",
        "    history_accuracy[\"train\"].append(epoch_acc)\n",
        "    history_f1[\"train\"].append(epoch_f1)\n",
        "    history_precision[\"train\"].append(epoch_precision)\n",
        "    history_recall[\"train\"].append(epoch_recall)\n",
        "\n",
        "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() -start_time))\n",
        "\n",
        "    \"\"\" Validation Phase \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        running_loss = 0.\n",
        "        running_corrects = 0\n",
        "        running_labels_preds = {\"labels\": [], \"preds\": []}\n",
        "\n",
        "        for inputs, labels in val_dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs  = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # store labels and preds and calculate f1, precision and recall at the end of the epoch\n",
        "            running_labels_preds[\"labels\"].append(labels.to('cpu').data.numpy())\n",
        "            running_labels_preds[\"preds\"].append(preds.to('cpu'))\n",
        "\n",
        "        epoch_loss = running_loss / len(val_dataset)\n",
        "        epoch_acc = running_corrects / len(val_dataset) * 100.\n",
        "\n",
        "        epoch_labels = np.concatenate((running_labels_preds['labels'][0],running_labels_preds['labels'][1]), axis=None)\n",
        "        epoch_preds = np.concatenate((running_labels_preds['preds'][0],running_labels_preds['preds'][1]), axis=None)\n",
        "        for i in range(2, len(running_labels_preds['labels'])):\n",
        "          epoch_labels = np.concatenate((epoch_labels,running_labels_preds['labels'][i]), axis=None)\n",
        "          epoch_preds = np.concatenate((epoch_preds,running_labels_preds['preds'][i]), axis=None)\n",
        "\n",
        "        epoch_f1 = f1_score(epoch_labels, epoch_preds)\n",
        "        epoch_precision = precision_score(epoch_labels, epoch_preds)\n",
        "        epoch_recall = recall_score(epoch_labels, epoch_preds)\n",
        "\n",
        "        history_loss[\"val\"].append(epoch_loss)\n",
        "        history_accuracy[\"val\"].append(epoch_acc)\n",
        "        history_f1[\"val\"].append(epoch_f1)\n",
        "        history_precision[\"val\"].append(epoch_precision)\n",
        "        history_recall[\"val\"].append(epoch_recall)\n",
        "\n",
        "        if epoch_acc > best_val_accuracy:\n",
        "          best_val_accuracy = epoch_acc\n",
        "          save_test_value = True\n",
        "        else:\n",
        "          save_test_value = False\n",
        "        print('[Val #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))\n",
        "        # early stopping\n",
        "        if early_stopper.early_stop(epoch_loss):\n",
        "          break\n",
        "\n",
        "    \"\"\" Testing Phase \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        running_loss = 0\n",
        "        running_corrects = 0\n",
        "        running_labels_preds = {\"labels\": [], \"preds\": []}\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(test_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs  = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # store labels and preds and calculate f1, precision and recall at the end of the epoch\n",
        "            running_labels_preds[\"labels\"].append(labels.to('cpu').data.numpy())\n",
        "            running_labels_preds[\"preds\"].append(preds.to('cpu'))\n",
        "\n",
        "        epoch_loss = running_loss / len(test_dataset)\n",
        "        epoch_acc = running_corrects / len(test_dataset) * 100.\n",
        "\n",
        "        epoch_labels = np.concatenate((running_labels_preds['labels'][0],running_labels_preds['labels'][1]), axis=None)\n",
        "        epoch_preds = np.concatenate((running_labels_preds['preds'][0],running_labels_preds['preds'][1]), axis=None)\n",
        "        for i in range(2, len(running_labels_preds['labels'])):\n",
        "          epoch_labels = np.concatenate((epoch_labels,running_labels_preds['labels'][i]), axis=None)\n",
        "          epoch_preds = np.concatenate((epoch_preds,running_labels_preds['preds'][i]), axis=None)\n",
        "\n",
        "        epoch_f1 = f1_score(epoch_labels, epoch_preds)\n",
        "        epoch_precision = precision_score(epoch_labels, epoch_preds)\n",
        "        epoch_recall = recall_score(epoch_labels, epoch_preds)\n",
        "\n",
        "        history_loss[\"test\"].append(epoch_loss)\n",
        "        history_accuracy[\"test\"].append(epoch_acc)\n",
        "        history_f1[\"test\"].append(epoch_f1)\n",
        "        history_precision[\"test\"].append(epoch_precision)\n",
        "        history_recall[\"test\"].append(epoch_recall)\n",
        "\n",
        "        if save_test_value == True:\n",
        "          best_test_accuracy = epoch_acc\n",
        "          best_test_f1 = epoch_f1\n",
        "          best_test_precision = epoch_precision\n",
        "          best_test_recall = epoch_recall\n",
        "        print('[Test #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S8MtLCEmPQ0",
        "outputId": "72b4cd51-6fa5-49e1-9dfd-4979afe3a2b7"
      },
      "outputs": [],
      "source": [
        "nb_classes = 2\n",
        "\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(test_dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "AO9WqozTaERz",
        "outputId": "cad71802-9308-4201-a17f-10cea3af0e99"
      },
      "outputs": [],
      "source": [
        "# Plot loss history\n",
        "plt.title(\"Loss\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_loss[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "GZZ8OEXaaE7L",
        "outputId": "017120da-cf89-4cc4-cbb6-c228e5d57bf9"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(history_accuracy[\"train\"])):\n",
        "  history_accuracy[\"train\"][i]=history_accuracy[\"train\"][i].cpu()\n",
        "for i in range(0, len(history_accuracy[\"val\"])):\n",
        "  history_accuracy[\"val\"][i]=history_accuracy[\"val\"][i].cpu()\n",
        "for i in range(0, len(history_accuracy[\"test\"])):\n",
        "  history_accuracy[\"test\"][i]=history_accuracy[\"test\"][i].cpu()\n",
        "\n",
        "# Plot accuracy history\n",
        "plt.title(\"Accuracy\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_accuracy[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "gJlA08fLpQzn",
        "outputId": "0c6d9acc-7949-4fe1-9397-ddad1cdcb415"
      },
      "outputs": [],
      "source": [
        "# Plot F1 history\n",
        "plt.title(\"F1 Score\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_f1[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "mWQT9qXcpQzn",
        "outputId": "ff17735b-e444-45aa-e1e9-2dbc778005e0"
      },
      "outputs": [],
      "source": [
        "# Plot precision history\n",
        "plt.title(\"Precision\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_precision[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "214yW_cGpQzn",
        "outputId": "f028dca6-d208-44a7-cf3f-bcf4b82559f1"
      },
      "outputs": [],
      "source": [
        "# Plot recall history\n",
        "plt.title(\"Recall\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_recall[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAw1ZQyAaHay",
        "outputId": "95f54fe0-8b3d-4e6b-ed97-33cbed3fe139"
      },
      "outputs": [],
      "source": [
        "print(best_test_accuracy)\n",
        "print(best_test_f1)\n",
        "print(best_test_precision)\n",
        "print(best_test_recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUBeYU2aaJcr"
      },
      "outputs": [],
      "source": [
        "save_path = 'inceptionv3_Adam_1.pth'\n",
        "torch.save(model.state_dict(), save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
