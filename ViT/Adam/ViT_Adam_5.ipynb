{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0xbrISIUcin",
        "outputId": "02ec9a86-96d1-48d6-f94e-a5e346ca120c"
      },
      "outputs": [],
      "source": [
        "# Get ViT-PyTorch\n",
        "!pip install --upgrade pytorch-pretrained-vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNV0yL0nF9qV",
        "outputId": "74e8a205-8f4e-4b18-eeab-0eebcc10f1b2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torchvision\n",
        "import time\n",
        "\n",
        "from pytorch_pretrained_vit import ViT\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"cuda available? \" + str(torch.cuda.is_available()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SevnM4aIuZz",
        "outputId": "f6ab53fe-888c-44e2-e5d0-89c9a8b40e3e"
      },
      "outputs": [],
      "source": [
        "# Define root directory from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "root_dir = \"/content/drive/My Drive/ceilometer_dataset1.1/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxPvDliNIGTD"
      },
      "outputs": [],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5)\n",
        "])\n",
        "\n",
        "# Augmentation on test images not needed\n",
        "transforms_test = torchvision.transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5)\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxTnEqM2IyqE"
      },
      "source": [
        "Structure of dataset folders\n",
        "```\n",
        "ceilometer_dataset\n",
        "    ----> train\n",
        "          ---->true\n",
        "          ---->false\n",
        "    ----> test\n",
        "          ---->true\n",
        "          ---->false\n",
        "\n",
        "70% train, 30% test\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-CuWEaFIzSL"
      },
      "outputs": [],
      "source": [
        "# remember to modify placeholders!\n",
        "train_dir = root_dir + \"train/\"\n",
        "test_dir = root_dir +\"test/\"\n",
        "train_classa_dir = root_dir + \"train/true/\"\n",
        "train_classb_dir = root_dir + \"train/false/\"\n",
        "test_classa_dir = root_dir + \"test/true/\"\n",
        "test_classb_dir = root_dir + \"test/false/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaihYR3kI5Ea"
      },
      "outputs": [],
      "source": [
        "train_datasets = datasets.ImageFolder(train_dir, transforms_train)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transforms_test)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_datasets, [round(len(train_datasets)*0.70), round(len(train_datasets)*0.30)])\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=2, drop_last=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=12, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=12, shuffle=False, num_workers=2, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVUi7a48I5Nw",
        "outputId": "63d5f58d-15b0-450c-eb91-69bea51cb966"
      },
      "outputs": [],
      "source": [
        "print('Train dataset size:', len(train_dataset))\n",
        "print('Validation dataset size:', len(val_dataset))\n",
        "print('Test dataset size:', len(test_dataset))\n",
        "class_names = test_dataset.classes\n",
        "print('Class names:', class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "ZiMnPS-lI9c3",
        "outputId": "441dfefe-bcf2-4581-fef7-6b0c008b52de"
      },
      "outputs": [],
      "source": [
        "# Random checking of train images\n",
        "im, label = train_dataset[100]\n",
        "print(im.shape)\n",
        "print(\"-------------\")\n",
        "print(label)\n",
        "plt.imshow(im.permute(1,2,0).cpu())\n",
        "print(\"Class: \", class_names[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6DjDVpcGUmA",
        "outputId": "c4ee07aa-ab1c-4206-afca-0a8f4a2ff049"
      },
      "outputs": [],
      "source": [
        "model_name = 'B_16_imagenet1k'\n",
        "model = ViT(model_name, pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()  #(set loss function)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKayjqFAzTp_",
        "outputId": "696292f2-a8bb-4b1c-f504-a3fbbac0885c"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnbB5QQ93yZ5"
      },
      "outputs": [],
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = np.inf\n",
        "\n",
        "    def early_stop(self, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5foFaayJCdd"
      },
      "outputs": [],
      "source": [
        "# Initialize training history\n",
        "# Initialize history\n",
        "history_loss = {\"train\": [], \"val\": [],\"test\": []}\n",
        "history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
        "history_f1 = {\"train\": [], \"val\": [], \"test\": []}\n",
        "history_precision = {\"train\": [], \"val\": [], \"test\": []}\n",
        "history_recall = {\"train\": [], \"val\": [], \"test\": []}\n",
        "\n",
        "# Initialize best validation accuracy and test accuracy at best validation accuracy\n",
        "best_val_accuracy = 0\n",
        "best_test_accuracy = 0\n",
        "best_test_f1 = 0\n",
        "best_test_precision = 0\n",
        "best_test_recall = 0\n",
        "save_test_value = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL4CyT1VJI2v",
        "outputId": "ddea8601-b47e-461f-f4fe-3b8fe5be987e"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60   #(set no of epochs)\n",
        "early_stopper = EarlyStopper(patience=3, min_delta=0.05)\n",
        "start_time = time.time() #(for showing time)\n",
        "for epoch in range(num_epochs): #(loop for every epoch)\n",
        "    print(\"Epoch {} running\".format(epoch)) #(printing message)\n",
        "    \"\"\" Training Phase \"\"\"\n",
        "    model.train()    #(training model)\n",
        "    running_loss = 0   #(set loss 0)\n",
        "    running_corrects = 0\n",
        "    running_labels_preds = {\"labels\": [], \"preds\": []}\n",
        "\n",
        "    # load a batch data of images\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # forward inputs and get output\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # get loss value and update the network weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # store labels and preds and calculate f1, precision and recall at the end of the epoch\n",
        "        running_labels_preds[\"labels\"].append(labels.to('cpu').data.numpy())\n",
        "        running_labels_preds[\"preds\"].append(preds.to('cpu'))\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
        "\n",
        "    epoch_labels = np.concatenate((running_labels_preds['labels'][0],running_labels_preds['labels'][1]), axis=None)\n",
        "    epoch_preds = np.concatenate((running_labels_preds['preds'][0],running_labels_preds['preds'][1]), axis=None)\n",
        "    for i in range(2, len(running_labels_preds['labels'])):\n",
        "      epoch_labels = np.concatenate((epoch_labels,running_labels_preds['labels'][i]), axis=None)\n",
        "      epoch_preds = np.concatenate((epoch_preds,running_labels_preds['preds'][i]), axis=None)\n",
        "\n",
        "    epoch_f1 = f1_score(epoch_labels, epoch_preds)\n",
        "    epoch_precision = precision_score(epoch_labels, epoch_preds)\n",
        "    epoch_recall = recall_score(epoch_labels, epoch_preds)\n",
        "\n",
        "    history_loss[\"train\"].append(epoch_loss)\n",
        "    history_accuracy[\"train\"].append(epoch_acc)\n",
        "    history_f1[\"train\"].append(epoch_f1)\n",
        "    history_precision[\"train\"].append(epoch_precision)\n",
        "    history_recall[\"train\"].append(epoch_recall)\n",
        "\n",
        "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() -start_time))\n",
        "\n",
        "    \"\"\" Validation Phase \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        running_loss = 0.\n",
        "        running_corrects = 0\n",
        "        running_labels_preds = {\"labels\": [], \"preds\": []}\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(val_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # store labels and preds and calculate f1, precision and recall at the end of the epoch\n",
        "            running_labels_preds[\"labels\"].append(labels.to('cpu').data.numpy())\n",
        "            running_labels_preds[\"preds\"].append(preds.to('cpu'))\n",
        "\n",
        "        epoch_loss = running_loss / len(val_dataset)\n",
        "        epoch_acc = running_corrects / len(val_dataset) * 100.\n",
        "\n",
        "        epoch_labels = np.concatenate((running_labels_preds['labels'][0],running_labels_preds['labels'][1]), axis=None)\n",
        "        epoch_preds = np.concatenate((running_labels_preds['preds'][0],running_labels_preds['preds'][1]), axis=None)\n",
        "        for i in range(2, len(running_labels_preds['labels'])):\n",
        "          epoch_labels = np.concatenate((epoch_labels,running_labels_preds['labels'][i]), axis=None)\n",
        "          epoch_preds = np.concatenate((epoch_preds,running_labels_preds['preds'][i]), axis=None)\n",
        "\n",
        "        epoch_f1 = f1_score(epoch_labels, epoch_preds)\n",
        "        epoch_precision = precision_score(epoch_labels, epoch_preds)\n",
        "        epoch_recall = recall_score(epoch_labels, epoch_preds)\n",
        "\n",
        "        history_loss[\"val\"].append(epoch_loss)\n",
        "        history_accuracy[\"val\"].append(epoch_acc)\n",
        "        history_f1[\"val\"].append(epoch_f1)\n",
        "        history_precision[\"val\"].append(epoch_precision)\n",
        "        history_recall[\"val\"].append(epoch_recall)\n",
        "\n",
        "        if epoch_acc > best_val_accuracy:\n",
        "          best_val_accuracy = epoch_acc\n",
        "          save_test_value = True\n",
        "        else:\n",
        "          save_test_value = False\n",
        "        print('[Val #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))\n",
        "        # early stopping\n",
        "        if early_stopper.early_stop(epoch_loss):\n",
        "          break\n",
        "\n",
        "    \"\"\" Testing Phase \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        running_loss = 0\n",
        "        running_corrects = 0\n",
        "        running_labels_preds = {\"labels\": [], \"preds\": []}\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(test_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # store labels and preds and calculate f1, precision and recall at the end of the epoch\n",
        "            running_labels_preds[\"labels\"].append(labels.to('cpu').data.numpy())\n",
        "            running_labels_preds[\"preds\"].append(preds.to('cpu'))\n",
        "\n",
        "        epoch_loss = running_loss / len(test_dataset)\n",
        "        epoch_acc = running_corrects / len(test_dataset) * 100.\n",
        "\n",
        "        epoch_labels = np.concatenate((running_labels_preds['labels'][0],running_labels_preds['labels'][1]), axis=None)\n",
        "        epoch_preds = np.concatenate((running_labels_preds['preds'][0],running_labels_preds['preds'][1]), axis=None)\n",
        "        for i in range(2, len(running_labels_preds['labels'])):\n",
        "          epoch_labels = np.concatenate((epoch_labels,running_labels_preds['labels'][i]), axis=None)\n",
        "          epoch_preds = np.concatenate((epoch_preds,running_labels_preds['preds'][i]), axis=None)\n",
        "\n",
        "        epoch_f1 = f1_score(epoch_labels, epoch_preds)\n",
        "        epoch_precision = precision_score(epoch_labels, epoch_preds)\n",
        "        epoch_recall = recall_score(epoch_labels, epoch_preds)\n",
        "\n",
        "        history_loss[\"test\"].append(epoch_loss)\n",
        "        history_accuracy[\"test\"].append(epoch_acc)\n",
        "        history_f1[\"test\"].append(epoch_f1)\n",
        "        history_precision[\"test\"].append(epoch_precision)\n",
        "        history_recall[\"test\"].append(epoch_recall)\n",
        "\n",
        "        if save_test_value == True:\n",
        "          best_test_accuracy = epoch_acc\n",
        "          best_test_f1 = epoch_f1\n",
        "          best_test_precision = epoch_precision\n",
        "          best_test_recall = epoch_recall\n",
        "        print('[Test #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDESkwOs4JYo",
        "outputId": "18866a3a-4d6b-4c22-b4ef-a3401263094e"
      },
      "outputs": [],
      "source": [
        "nb_classes = 2\n",
        "\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(test_dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "FgOKdxdbJNps",
        "outputId": "f3bf8581-b980-44e6-a99b-c1250f16097d"
      },
      "outputs": [],
      "source": [
        "# Plot loss history\n",
        "plt.title(\"Loss\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_loss[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "DjJWSSu1JOFj",
        "outputId": "8fcd0349-d3ab-46c0-f81a-f8c0e92fe63a"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(history_accuracy[\"train\"])):\n",
        "  history_accuracy[\"train\"][i]=history_accuracy[\"train\"][i].cpu()\n",
        "for i in range(0, len(history_accuracy[\"val\"])):\n",
        "  history_accuracy[\"val\"][i]=history_accuracy[\"val\"][i].cpu()\n",
        "for i in range(0, len(history_accuracy[\"test\"])):\n",
        "  history_accuracy[\"test\"][i]=history_accuracy[\"test\"][i].cpu()\n",
        "\n",
        "# Plot accuracy history\n",
        "plt.title(\"Accuracy\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_accuracy[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "_rRw7NMezTqB",
        "outputId": "cbc872da-37f4-4876-b65a-e23a3766fde2"
      },
      "outputs": [],
      "source": [
        "# Plot F1 history\n",
        "plt.title(\"F1 Score\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_f1[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "DZcsJyh7zTqB",
        "outputId": "86cd4b46-c35a-4d14-b8a1-b1585595942d"
      },
      "outputs": [],
      "source": [
        "# Plot precision history\n",
        "plt.title(\"Precision\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_precision[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "ICXMdyz3zTqB",
        "outputId": "78ed7f92-aefb-4c0c-e5a2-20c3c4746f19"
      },
      "outputs": [],
      "source": [
        "# Plot recall history\n",
        "plt.title(\"Recall\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_recall[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqAz8WrdJP3y",
        "outputId": "2336c648-a2c5-42e5-8817-9ae0a1084dde"
      },
      "outputs": [],
      "source": [
        "print(best_test_accuracy)\n",
        "print(best_test_f1)\n",
        "print(best_test_precision)\n",
        "print(best_test_recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7Davr4AJR93"
      },
      "outputs": [],
      "source": [
        "save_path = 'ViT_Adam_5.pth'\n",
        "torch.save(model.state_dict(), save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
