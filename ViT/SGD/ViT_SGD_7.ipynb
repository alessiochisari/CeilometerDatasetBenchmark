{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0xbrISIUcin",
        "outputId": "17bff002-eec4-46ab-c0f0-f957a8879bf5"
      },
      "outputs": [],
      "source": [
        "# Get ViT-PyTorch\n",
        "!pip install --upgrade pytorch-pretrained-vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNV0yL0nF9qV",
        "outputId": "bfdf48d6-6058-4e29-fa2f-8c47a82ad21e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import torchvision\n",
        "import time\n",
        "\n",
        "from pytorch_pretrained_vit import ViT\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"cuda available? \" + str(torch.cuda.is_available()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SevnM4aIuZz",
        "outputId": "b398edc3-7707-4423-c348-cc309f9cfd3e"
      },
      "outputs": [],
      "source": [
        "# Define root directory from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "root_dir = \"/content/drive/My Drive/ceilometer_dataset1.1/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxPvDliNIGTD"
      },
      "outputs": [],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5)\n",
        "])\n",
        "\n",
        "# Augmentation on test images not needed\n",
        "transforms_test = torchvision.transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5)\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxTnEqM2IyqE"
      },
      "source": [
        "Structure of dataset folders\n",
        "```\n",
        "ceilometer_dataset\n",
        "    ----> train\n",
        "          ---->true\n",
        "          ---->false\n",
        "    ----> test\n",
        "          ---->true\n",
        "          ---->false\n",
        "\n",
        "70% train, 30% test\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-CuWEaFIzSL"
      },
      "outputs": [],
      "source": [
        "# remember to modify placeholders!\n",
        "train_dir = root_dir + \"train/\"\n",
        "test_dir = root_dir +\"test/\"\n",
        "train_classa_dir = root_dir + \"train/true/\"\n",
        "train_classb_dir = root_dir + \"train/false/\"\n",
        "test_classa_dir = root_dir + \"test/true/\"\n",
        "test_classb_dir = root_dir + \"test/false/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaihYR3kI5Ea"
      },
      "outputs": [],
      "source": [
        "train_datasets = datasets.ImageFolder(train_dir, transforms_train)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transforms_test)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_datasets, [round(len(train_datasets)*0.70), round(len(train_datasets)*0.30)])\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=2, drop_last=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=12, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=12, shuffle=False, num_workers=2, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVUi7a48I5Nw",
        "outputId": "335e80a1-3305-4278-eae4-1118acfcb102"
      },
      "outputs": [],
      "source": [
        "print('Train dataset size:', len(train_dataset))\n",
        "print('Validation dataset size:', len(val_dataset))\n",
        "print('Test dataset size:', len(test_dataset))\n",
        "class_names = test_dataset.classes\n",
        "print('Class names:', class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "ZiMnPS-lI9c3",
        "outputId": "f5218723-8522-47a9-baad-c7c473f83d2f"
      },
      "outputs": [],
      "source": [
        "# Random checking of train images\n",
        "im, label = train_dataset[100]\n",
        "print(im.shape)\n",
        "print(\"-------------\")\n",
        "print(label)\n",
        "plt.imshow(im.permute(1,2,0).cpu())\n",
        "print(\"Class: \", class_names[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6DjDVpcGUmA",
        "outputId": "2cf6917b-81d5-4c06-d5f5-8d55db3ed857"
      },
      "outputs": [],
      "source": [
        "model_name = 'B_16_imagenet1k'\n",
        "model = ViT(model_name, pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()  #(set loss function)\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.8, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nesmm2KxZkr1",
        "outputId": "814df619-9647-47fa-b8ee-eac6a2a58708"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnbB5QQ93yZ5"
      },
      "outputs": [],
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.min_validation_loss = np.inf\n",
        "\n",
        "    def early_stop(self, validation_loss):\n",
        "        if validation_loss < self.min_validation_loss:\n",
        "            self.min_validation_loss = validation_loss\n",
        "            self.counter = 0\n",
        "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5foFaayJCdd"
      },
      "outputs": [],
      "source": [
        "# Initialize training history\n",
        "# Initialize history\n",
        "history_loss = {\"train\": [], \"val\": [],\"test\": []}\n",
        "history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
        "history_f1 = {\"train\": [], \"val\": [], \"test\": []}\n",
        "history_precision = {\"train\": [], \"val\": [], \"test\": []}\n",
        "history_recall = {\"train\": [], \"val\": [], \"test\": []}\n",
        "\n",
        "# Initialize best validation accuracy and test accuracy at best validation accuracy\n",
        "best_val_accuracy = 0\n",
        "best_test_accuracy = 0\n",
        "best_test_f1 = 0\n",
        "best_test_precision = 0\n",
        "best_test_recall = 0\n",
        "save_test_value = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL4CyT1VJI2v",
        "outputId": "2205de5d-318e-4876-f9d0-ad990a6eedb1"
      },
      "outputs": [],
      "source": [
        "num_epochs = 60   #(set no of epochs)\n",
        "early_stopper = EarlyStopper(patience=3, min_delta=0.05)\n",
        "start_time = time.time() #(for showing time)\n",
        "for epoch in range(num_epochs): #(loop for every epoch)\n",
        "    print(\"Epoch {} running\".format(epoch)) #(printing message)\n",
        "    \"\"\" Training Phase \"\"\"\n",
        "    model.train()    #(training model)\n",
        "    running_loss = 0   #(set loss 0)\n",
        "    running_corrects = 0\n",
        "    running_labels_preds = {\"labels\": [], \"preds\": []}\n",
        "\n",
        "    # load a batch data of images\n",
        "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        # forward inputs and get output\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # get loss value and update the network weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # store labels and preds and calculate f1, precision and recall at the end of the epoch\n",
        "        running_labels_preds[\"labels\"].append(labels.to('cpu').data.numpy())\n",
        "        running_labels_preds[\"preds\"].append(preds.to('cpu'))\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = running_corrects / len(train_dataset) * 100.\n",
        "\n",
        "    epoch_labels = np.concatenate((running_labels_preds['labels'][0],running_labels_preds['labels'][1]), axis=None)\n",
        "    epoch_preds = np.concatenate((running_labels_preds['preds'][0],running_labels_preds['preds'][1]), axis=None)\n",
        "    for i in range(2, len(running_labels_preds['labels'])):\n",
        "      epoch_labels = np.concatenate((epoch_labels,running_labels_preds['labels'][i]), axis=None)\n",
        "      epoch_preds = np.concatenate((epoch_preds,running_labels_preds['preds'][i]), axis=None)\n",
        "\n",
        "    epoch_f1 = f1_score(epoch_labels, epoch_preds)\n",
        "    epoch_precision = precision_score(epoch_labels, epoch_preds)\n",
        "    epoch_recall = recall_score(epoch_labels, epoch_preds)\n",
        "\n",
        "    history_loss[\"train\"].append(epoch_loss)\n",
        "    history_accuracy[\"train\"].append(epoch_acc)\n",
        "    history_f1[\"train\"].append(epoch_f1)\n",
        "    history_precision[\"train\"].append(epoch_precision)\n",
        "    history_recall[\"train\"].append(epoch_recall)\n",
        "\n",
        "    print('[Train #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() -start_time))\n",
        "\n",
        "    \"\"\" Validation Phase \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        running_loss = 0.\n",
        "        running_corrects = 0\n",
        "        running_labels_preds = {\"labels\": [], \"preds\": []}\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(val_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # store labels and preds and calculate f1, precision and recall at the end of the epoch\n",
        "            running_labels_preds[\"labels\"].append(labels.to('cpu').data.numpy())\n",
        "            running_labels_preds[\"preds\"].append(preds.to('cpu'))\n",
        "\n",
        "        epoch_loss = running_loss / len(val_dataset)\n",
        "        epoch_acc = running_corrects / len(val_dataset) * 100.\n",
        "\n",
        "        epoch_labels = np.concatenate((running_labels_preds['labels'][0],running_labels_preds['labels'][1]), axis=None)\n",
        "        epoch_preds = np.concatenate((running_labels_preds['preds'][0],running_labels_preds['preds'][1]), axis=None)\n",
        "        for i in range(2, len(running_labels_preds['labels'])):\n",
        "          epoch_labels = np.concatenate((epoch_labels,running_labels_preds['labels'][i]), axis=None)\n",
        "          epoch_preds = np.concatenate((epoch_preds,running_labels_preds['preds'][i]), axis=None)\n",
        "\n",
        "        epoch_f1 = f1_score(epoch_labels, epoch_preds)\n",
        "        epoch_precision = precision_score(epoch_labels, epoch_preds)\n",
        "        epoch_recall = recall_score(epoch_labels, epoch_preds)\n",
        "\n",
        "        history_loss[\"val\"].append(epoch_loss)\n",
        "        history_accuracy[\"val\"].append(epoch_acc)\n",
        "        history_f1[\"val\"].append(epoch_f1)\n",
        "        history_precision[\"val\"].append(epoch_precision)\n",
        "        history_recall[\"val\"].append(epoch_recall)\n",
        "\n",
        "        if epoch_acc > best_val_accuracy:\n",
        "          best_val_accuracy = epoch_acc\n",
        "          save_test_value = True\n",
        "        else:\n",
        "          save_test_value = False\n",
        "        print('[Val #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))\n",
        "        # early stopping\n",
        "        if early_stopper.early_stop(epoch_loss):\n",
        "          break\n",
        "\n",
        "    \"\"\" Testing Phase \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        running_loss = 0\n",
        "        running_corrects = 0\n",
        "        running_labels_preds = {\"labels\": [], \"preds\": []}\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(test_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # store labels and preds and calculate f1, precision and recall at the end of the epoch\n",
        "            running_labels_preds[\"labels\"].append(labels.to('cpu').data.numpy())\n",
        "            running_labels_preds[\"preds\"].append(preds.to('cpu'))\n",
        "\n",
        "        epoch_loss = running_loss / len(test_dataset)\n",
        "        epoch_acc = running_corrects / len(test_dataset) * 100.\n",
        "\n",
        "        epoch_labels = np.concatenate((running_labels_preds['labels'][0],running_labels_preds['labels'][1]), axis=None)\n",
        "        epoch_preds = np.concatenate((running_labels_preds['preds'][0],running_labels_preds['preds'][1]), axis=None)\n",
        "        for i in range(2, len(running_labels_preds['labels'])):\n",
        "          epoch_labels = np.concatenate((epoch_labels,running_labels_preds['labels'][i]), axis=None)\n",
        "          epoch_preds = np.concatenate((epoch_preds,running_labels_preds['preds'][i]), axis=None)\n",
        "\n",
        "        epoch_f1 = f1_score(epoch_labels, epoch_preds)\n",
        "        epoch_precision = precision_score(epoch_labels, epoch_preds)\n",
        "        epoch_recall = recall_score(epoch_labels, epoch_preds)\n",
        "\n",
        "        history_loss[\"test\"].append(epoch_loss)\n",
        "        history_accuracy[\"test\"].append(epoch_acc)\n",
        "        history_f1[\"test\"].append(epoch_f1)\n",
        "        history_precision[\"test\"].append(epoch_precision)\n",
        "        history_recall[\"test\"].append(epoch_recall)\n",
        "\n",
        "        if save_test_value == True:\n",
        "          best_test_accuracy = epoch_acc\n",
        "          best_test_f1 = epoch_f1\n",
        "          best_test_precision = epoch_precision\n",
        "          best_test_recall = epoch_recall\n",
        "        print('[Test #{}] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time()- start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDESkwOs4JYo",
        "outputId": "933c6c6b-d856-4323-cee9-66b959d9860a"
      },
      "outputs": [],
      "source": [
        "nb_classes = 2\n",
        "\n",
        "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, classes) in enumerate(test_dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        classes = classes.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
        "                confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "print(confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "FgOKdxdbJNps",
        "outputId": "4df36a6c-1732-4f2e-eaf4-6ad13d65de50"
      },
      "outputs": [],
      "source": [
        "# Plot loss history\n",
        "plt.title(\"Loss\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_loss[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "DjJWSSu1JOFj",
        "outputId": "1d13e991-5c0c-42df-e40e-9d9d244fbe20"
      },
      "outputs": [],
      "source": [
        "for i in range(0, len(history_accuracy[\"train\"])):\n",
        "  history_accuracy[\"train\"][i]=history_accuracy[\"train\"][i].cpu()\n",
        "for i in range(0, len(history_accuracy[\"val\"])):\n",
        "  history_accuracy[\"val\"][i]=history_accuracy[\"val\"][i].cpu()\n",
        "for i in range(0, len(history_accuracy[\"test\"])):\n",
        "  history_accuracy[\"test\"][i]=history_accuracy[\"test\"][i].cpu()\n",
        "\n",
        "# Plot accuracy history\n",
        "plt.title(\"Accuracy\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_accuracy[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "-cyWWTGNZkr3",
        "outputId": "e0bce4ec-94dd-442e-93fd-3a53a5a11a02"
      },
      "outputs": [],
      "source": [
        "# Plot F1 history\n",
        "plt.title(\"F1 Score\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_f1[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "yuw9Qy26Zkr4",
        "outputId": "e366e986-304b-4440-d9c2-b06c41f79a17"
      },
      "outputs": [],
      "source": [
        "# Plot precision history\n",
        "plt.title(\"Precision\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_precision[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "5L78nSMxZkr4",
        "outputId": "8613148e-7789-4d20-c0e7-23579a7b83d7"
      },
      "outputs": [],
      "source": [
        "# Plot recall history\n",
        "plt.title(\"Recall\")\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "  plt.plot(history_recall[split], label=split)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqAz8WrdJP3y",
        "outputId": "7054404f-6fde-41ad-e5cb-fb146dc141d9"
      },
      "outputs": [],
      "source": [
        "print(best_test_accuracy)\n",
        "print(best_test_f1)\n",
        "print(best_test_precision)\n",
        "print(best_test_recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7Davr4AJR93"
      },
      "outputs": [],
      "source": [
        "save_path = 'ViT_SGD_7.pth'\n",
        "torch.save(model.state_dict(), save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
